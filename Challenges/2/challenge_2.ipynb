{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55d5de70",
      "metadata": {
        "id": "55d5de70"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "import random\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "df_x = pd.read_csv('./padel_83_1490.csv', index_col=0)  # Atributos (Eliminamos la primera columna \"molecula: mol_1, mol2,...\")\n",
        "df_y = pd.read_csv('./FEB_catechol83.csv', index_col=0) # Target (Eliminamos la primera columna \"index_mol: 1, 2, 3, 4\")\n",
        "df_x_rfe = df_x\n",
        "df_y_rfe = df_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Selección de Características de Acuerdo a Recursive Feature Elimination"
      ],
      "metadata": {
        "id": "rgChD_0ooWGH"
      },
      "id": "rgChD_0ooWGH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos caracteristicas con el 90% de valores iguales a 0\n",
        "ceros_por_columna = (df_x_rfe == 0).sum()\n",
        "columnas_a_eliminar = ceros_por_columna[ceros_por_columna >= 73].index.tolist()\n",
        "df_x_rfe = df_x_rfe.drop(columns=columnas_a_eliminar)\n",
        "\n",
        "# Con el dataset reducido aplicamos RFE\n",
        "y = df_y_rfe.values\n",
        "X = df_x_rfe.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "modelo_base = RandomForestRegressor(n_estimators=100, random_state=42) # Aplicar RFE para seleccionar las 131 mejores características\n",
        "rfe = RFE(estimator=modelo_base, n_features_to_select=131)\n",
        "rfe.fit(X_train, y_train.ravel())\n",
        "\n",
        "columnas_seleccionadas = df_x_rfe.columns[rfe.support_] # Obtener columnas seleccionadas\n",
        "print(\"\\nColumnas seleccionadas por RFE:\")\n",
        "print(columnas_seleccionadas.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xJMWG2VoU2H",
        "outputId": "ccda3375-9b0f-42c9-b80a-7cffda763c10"
      },
      "id": "-xJMWG2VoU2H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columnas seleccionadas por RFE:\n",
            "['AMR', 'AATS6m', 'AATS5v', 'AATS5e', 'AATS7e', 'AATS5p', 'AATS4i', 'AATS7i', 'AATS4s', 'ATSC2c', 'ATSC4c', 'ATSC8c', 'ATSC6m', 'ATSC7v', 'ATSC7e', 'ATSC6p', 'ATSC7p', 'ATSC7i', 'ATSC3s', 'ATSC5s', 'ATSC6s', 'ATSC8s', 'AATSC2c', 'AATSC8m', 'AATSC5v', 'AATSC4e', 'AATSC5e', 'AATSC7e', 'AATSC2p', 'AATSC8p', 'AATSC2i', 'AATSC7s', 'MATS5c', 'MATS5m', 'MATS4e', 'MATS7e', 'MATS2p', 'MATS6p', 'MATS7p', 'MATS8p', 'MATS2i', 'MATS6i', 'MATS7i', 'MATS2s', 'MATS5s', 'MATS7s', 'GATS7c', 'GATS2m', 'GATS5v', 'GATS6v', 'GATS7v', 'GATS1e', 'GATS4e', 'GATS5e', 'GATS6e', 'GATS1p', 'GATS2i', 'GATS1s', 'GATS2s', 'GATS7s', 'VE3_DzZ', 'VE2_Dzv', 'VR2_Dzv', 'VE1_Dze', 'VE2_Dze', 'VR1_Dzi', 'VR2_Dzi', 'VR3_Dzi', 'VE3_Dzs', 'VR1_Dzs', 'VR2_Dzs', 'BCUTw-1h', 'BCUTc-1l', 'nBondsM', 'SpMax3_Bhm', 'SpMin3_Bhm', 'SpMin4_Bhm', 'SpMin6_Bhm', 'SpMax2_Bhv', 'SpMin5_Bhv', 'SpMax2_Bhe', 'SpMin2_Bhe', 'SpMax2_Bhi', 'SpMax8_Bhs', 'SpMin2_Bhs', 'SpMin3_Bhs', 'SC-3', 'VC-3', 'VPC-5', 'ASP-0', 'VP-6', 'VE1_Dt', 'VE2_Dt', 'VE3_Dt', 'nHaaCH', 'nHother', 'SwHBa', 'SHBint3', 'SHBint4', 'SHaaCH', 'SHother', 'SaaCH', 'SdO', 'SssO', 'minHsOH', 'minHother', 'minsCH3', 'minaasC', 'mindO', 'minssO', 'maxwHBa', 'maxHBint9', 'maxsOH', 'ETA_Shape_Y', 'ETA_Beta_ns', 'ETA_dBetaP', 'IC1', 'IC5', 'SIC1', 'CIC5', 'BIC5', 'MIC0', 'ZMIC4', 'ZMIC5', 'GGI7', 'JGI3', 'JGI6', 'JGI8', 'JGI9', 'SpMAD_D', 'VE3_D']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Selección de Características de Acuerdo al Paper"
      ],
      "metadata": {
        "id": "ivUqkaeZoIA3"
      },
      "id": "ivUqkaeZoIA3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5df004ec",
      "metadata": {
        "id": "5df004ec"
      },
      "outputs": [],
      "source": [
        "columnas_relevantes = [\n",
        "    'SHaaCH', 'SpMin3_Bhm', 'VE3_Dzi', 'SpMax2_Bhe', 'SaaCH', 'SpMax2_Bhp', 'AATSC2s', 'MLFER_L', 'SpMin3_Bhs', 'SpMax2_Bhi',\n",
        "    'VE2_Dt', 'SHother', 'SpDiam_Dt', 'SpMax2_Bhv', 'GATS2s', 'hmin', 'JGI3', 'SpMax2_Bhm', 'VR2_Dt', 'SpMin3_Bhe', 'nBondsM',\n",
        "    'ATSC2s', 'ATSC2c', 'SwHBa', 'ASP-0', 'minHBa', 'ETA_Beta_ns', 'IC5', 'VR1_Dzm', 'ATS2v', 'MLogP', 'SpMin2_Bhs',\n",
        "    'maxHBa', 'ATSC4m', 'ATSC4s', 'AATSC7e', 'VE3_Dt', 'VR2_Dzi', 'ETA_Shape_P', 'SpMin2_Bhv', 'VP-5', 'AATS6p', 'VE1_Dzi',\n",
        "    'minHother', 'MATS5e', 'SpMax7_Bhm', 'VP-6', 'SpMax3_Bhp', 'GATS1s', 'VE3_Dzm', 'VR1_Dze', 'ATS3v', 'SpMin2_Bhe',\n",
        "    'ATS2s', 'MLFER_BO', 'GATS7c', 'VR1_Dzi', 'AATSC2c', 'ATSC1m', 'MLFER_BH', 'MATS4s', 'AATSC4c', 'MATS2s', 'VE3_Dze',\n",
        "    'ZMIC4', 'AATSC4s', 'SaasC', 'AATSC8e', 'MAXDP', 'GATS1e', 'AATS7i', 'AATSC8s', 'AATSC5c', 'AATS8i', 'EE_Dt',\n",
        "    'AATSC5e', 'SpMax3_Bhi', 'ATSC3p', 'VE3_DzZ', 'MATS2p', 'SpMAD_D', 'MATS5m', 'IC4', 'VE1_Dt', 'VR3_Dzp', 'SpMax3_Bhv',\n",
        "    'ATSC5e', 'MATS2i', 'SpMAD_Dzs', 'MATS7e', 'SpMin3_Bhi', 'VE2_Dzi', 'MIC2', 'AATSC6p', 'SpMax6_Bhi', 'VR1_DzZ',\n",
        "    'VE2_DzZ', 'CIC4', 'SpMin2_Bhm', 'AATSC4e', 'VE1_DzZ', 'VE3_D', 'MATS3i', 'ATSC5c', 'VR3_Dzv', 'AATSC2i', 'MATS5c',\n",
        "    'SpMin2_Bhp', 'SpMin3_Bhp', 'MAXDP2', 'ATSC7s', 'MATS5s', 'SpMin8_Bhs', 'ATSC3i', 'VE2_Dze', 'GATS2m', 'AATSC5v',\n",
        "    'MIC5', 'SpMin2_Bhi', 'ATSC7e', 'SpMax3_Bhm', 'ATSC8e', 'BCUTp-1l', 'AATSC2v', 'VE1_Dze', 'ATS6p', 'GATS6p',\n",
        "    'VR3_Dzi', 'ATS1s', 'MATS2v', 'piPC2'\n",
        "]\n",
        "df_x_filt = df_x[columnas_relevantes] # Filtramos el dataset con las columnas relevantes\n",
        "X = df_x_filt.values    # Features\n",
        "y = df_y.values  # Target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Evaluación del modelo K Nearest Neighbors"
      ],
      "metadata": {
        "id": "VqlXyAojnsER"
      },
      "id": "VqlXyAojnsER"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "knn = KNeighborsRegressor(n_neighbors=7)\n",
        "knn.fit(X_train, y_train.ravel())\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_knn)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
        "mse = mean_squared_error(y_test, y_pred_knn)\n",
        "mae = mean_absolute_error(y_test, y_pred_knn)\n",
        "\n",
        "print(f'R²:   {r2:.4f}')\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "print(f'MSE:  {mse:.4f}')\n",
        "print(f'MAE:  {mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEBWcPwmVUD",
        "outputId": "1ff10765-839c-4906-b83c-6aab4bb713bf"
      },
      "id": "KLEBWcPwmVUD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R²:   0.6803\n",
            "RMSE: 0.0833\n",
            "MSE:  0.0069\n",
            "MAE:  0.0672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluación de Redes Neuronales"
      ],
      "metadata": {
        "id": "8wp68xeSn5Xf"
      },
      "id": "8wp68xeSn5Xf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb5a6ab",
      "metadata": {
        "id": "3fb5a6ab"
      },
      "outputs": [],
      "source": [
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)           # train (60%), val (20%), test (20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3c8545",
      "metadata": {
        "id": "dc3c8545"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=13):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79903bb0",
      "metadata": {
        "id": "79903bb0",
        "outputId": "b407da58-4fb4-4768-8262-1babba532d92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">helpful-aardvark-31</strong> at: <a href='https://wandb.ai/zerocris13/challenge2/runs/aw0fzi18' target=\"_blank\">https://wandb.ai/zerocris13/challenge2/runs/aw0fzi18</a><br> View project at: <a href='https://wandb.ai/zerocris13/challenge2' target=\"_blank\">https://wandb.ai/zerocris13/challenge2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20250414_122234-aw0fzi18\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>d:\\1. Ingeniería Biomédica\\12 CICLO\\Reconocimiento de Patrones\\Challenges\\2\\wandb\\run-20250414_122336-296k5bxm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zerocris13/challenge2/runs/296k5bxm' target=\"_blank\">dutiful-night-32</a></strong> to <a href='https://wandb.ai/zerocris13/challenge2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/zerocris13/challenge2' target=\"_blank\">https://wandb.ai/zerocris13/challenge2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/zerocris13/challenge2/runs/296k5bxm' target=\"_blank\">https://wandb.ai/zerocris13/challenge2/runs/296k5bxm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.init(project=\"challenge2\", entity=\"zerocris13\")\n",
        "class CompactNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(16, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = CompactNN(X_train_tensor.shape[1]).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr= 0.0038576, weight_decay= 0.0067415)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e122d8eb",
      "metadata": {
        "id": "e122d8eb",
        "outputId": "be9f6c23-59b0-4e20-9b77-2bf67e9b751d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stopping en epoch 36\n"
          ]
        }
      ],
      "source": [
        "epochs = 300\n",
        "batch_size = 16\n",
        "patience = 25\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    permutation = torch.randperm(X_train_tensor.size(0))\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        if len(indices) < 2: continue  # evitar lote de 1 muestra\n",
        "\n",
        "        x_batch = X_train_tensor[indices]\n",
        "        y_batch = y_train_tensor[indices]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                wandb.log({f\"gradients/{name}\": param.grad.norm().item(), \"epoch\": epoch + 1})\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_output = model(X_val_tensor)\n",
        "        val_loss = criterion(val_output, y_val_tensor).item()\n",
        "\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss / (X_train_tensor.size(0) // batch_size),\n",
        "        \"val_loss\": val_loss\n",
        "    })\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), \"model_val.pth\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping en epoch {epoch+1}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd1c366",
      "metadata": {
        "id": "dfd1c366",
        "outputId": "fccdaf2f-8af1-4473-c662-e7f8465b3eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train metrics:\n",
            "R²:   0.8585\n",
            "RMSE: 0.2498\n",
            "MSE:  0.0624\n",
            "MAE:  0.1954\n",
            "Test metrics:\n",
            "R²:   0.8207\n",
            "RMSE: 0.2183\n",
            "MSE:  0.0477\n",
            "MAE:  0.1591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25036\\3669171316.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model_val.pth\"))\n",
            "c:\\Users\\HP\\miniconda3\\envs\\cscience\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "c:\\Users\\HP\\miniconda3\\envs\\cscience\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"best_model_val.pth\"))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_tensor = model(X_test_tensor).cpu().squeeze()\n",
        "    y_true_tensor = y_test_tensor.cpu().squeeze()\n",
        "    train_y_pred_tensor = model(X_train_tensor).cpu().squeeze()\n",
        "    train_y_true_tensor = y_train_tensor.cpu().squeeze()\n",
        "\n",
        "y_pred = y_pred_tensor.numpy()\n",
        "y_true = y_true_tensor.numpy()\n",
        "\n",
        "train_y_pred = train_y_pred_tensor.numpy()\n",
        "train_y_true = train_y_true_tensor.numpy()\n",
        "\n",
        "# Train\n",
        "train_r2 = r2_score(train_y_true, train_y_pred)\n",
        "train_rmse = mean_squared_error(train_y_true, train_y_pred, squared=False)\n",
        "train_mse = mean_squared_error(train_y_true, train_y_pred)\n",
        "train_mae = mean_absolute_error(train_y_true, train_y_pred)\n",
        "\n",
        "# Test\n",
        "test_r2 = r2_score(y_true, y_pred)\n",
        "test_rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "test_mse = mean_squared_error(y_true, y_pred)\n",
        "test_mae = mean_absolute_error(y_true, y_pred)\n",
        "print(\"Train metrics:\")\n",
        "print(f\"R²:   {train_r2:.4f}\")\n",
        "print(f\"RMSE: {train_rmse:.4f}\")\n",
        "print(f\"MSE:  {train_mse:.4f}\")\n",
        "print(f\"MAE:  {train_mae:.4f}\")\n",
        "\n",
        "print(\"Test metrics:\")\n",
        "print(f\"R²:   {test_r2:.4f}\")\n",
        "print(f\"RMSE: {test_rmse:.4f}\")\n",
        "print(f\"MSE:  {test_mse:.4f}\")\n",
        "print(f\"MAE:  {test_mae:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}